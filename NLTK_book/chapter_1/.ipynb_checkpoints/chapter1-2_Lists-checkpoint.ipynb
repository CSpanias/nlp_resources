{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f2dec07",
   "metadata": {},
   "source": [
    "# **Natural Language Processing with Python**\n",
    "by [CSpanias](https://cspanias.github.io/aboutme/) - 01/2022\n",
    "\n",
    "Content based on the [NLTK book](https://www.nltk.org/book/). <br>\n",
    "\n",
    "You can find Chapter 1 [here](https://www.nltk.org/book/ch01.html).\n",
    "\n",
    "# CONTENT\n",
    "\n",
    "1. Language Processing and Python\n",
    "    1. Computing with Language: Texts and Words\n",
    "    2. [A Closer Look at Python: Texts as Lists of Words](#ListsofWords)\n",
    "        1. [Lists](#Lists) <br>\n",
    "        1. [Indexing Lists](#Indeces) <br>\n",
    "        1. [Strings](#Strings) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385d370d",
   "metadata": {},
   "source": [
    "**Install**, **import** and **download NLTK**. <br>\n",
    "\n",
    "*Uncomment lines 2 and 5 if you haven't installed and downloaded NLTK yet.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2abe7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install nltk\n",
    "#!pip install nltk\n",
    "\n",
    "# load nltk\n",
    "import nltk\n",
    "\n",
    "# download nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79726eee",
   "metadata": {},
   "source": [
    "Load all items (9 texts) from **NLTK' book module**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68c69572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "# load all items from NLTKâ€™s book module.\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ee7b54",
   "metadata": {},
   "source": [
    "<a name=\"ListsofWords\"></a>\n",
    "## 1.2 A Closer Look at Python: Texts as Lists of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a614c7",
   "metadata": {},
   "source": [
    "<a name=\"Lists\"></a>\n",
    "### 2.1 Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079f6f91",
   "metadata": {},
   "source": [
    "`set(list)` removes duplicate elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5c12b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list with 200 words\n",
    "word_list = text1[2300:2500]\n",
    "# print the length of the list\n",
    "print(len(word_list))\n",
    "# remove duplicates from the list\n",
    "new_word_list = set(word_list)\n",
    "# count the length of the new list\n",
    "len(new_word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d26007",
   "metadata": {},
   "source": [
    "We can **combine the elements of two seperate lists into a single list** using **concatenation**.\n",
    "\n",
    "**Syntax**: `list_1 + list_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "84fef3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_1 = [1, 2, 3]\n",
    "list_2 = [4, 5, 6]\n",
    "list_1 + list_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736750b1",
   "metadata": {},
   "source": [
    "<a name=\"Indeces\"></a>\n",
    "### 2.2 Indexing Lists\n",
    "We can find the element at the specified position of a list.\n",
    "\n",
    ">The number that represents this position is the item's **index**.\n",
    "\n",
    "**Syntax**:`text[index]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6664c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'That'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the number at position 1501\n",
    "text1[1501]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86559927",
   "metadata": {},
   "source": [
    "We can also do the opposite; find the index of the specified element.\n",
    "\n",
    "**Syntax**: `text[element]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7db89ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1501"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the index of the specified word\n",
    "text1.index(\"That\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e013c2e1",
   "metadata": {},
   "source": [
    "**Slicing** permits us to **access sublists**,i.e. manageable pieces of language from large texts.\n",
    "\n",
    "**Syntax**: `text[m:n-1]` \n",
    "\n",
    ">`text[0:5]` would result to a total of 5 words. **The $2^{nd}$ value defined**, i.e. the item at the 5$^{th}$ position, **is exclusive**. Hence, it would give the elements with index 0, 1, 2, 3 and 4, but not the item on the 5$^{th}$ position!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67524b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', '1851', ']', 'ETYMOLOGY', '.']\n"
     ]
    }
   ],
   "source": [
    "# get the 10 words of text1\n",
    "print(text1[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93046d69",
   "metadata": {},
   "source": [
    "We can **replace an entire slice** with new elements.\n",
    "\n",
    "**Syntax**: `list[m:n-1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7222c907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 9, 8, 4, 5]\n",
      "[1, 0, 9, 8]\n"
     ]
    }
   ],
   "source": [
    "my_list = [1, 2, 3, 4, 5]\n",
    "# replace the items from index 1 to 3\n",
    "my_list[1:3] = [0, 9, 8]\n",
    "# print list\n",
    "print(my_list)\n",
    "\n",
    "# replace the items from index 1 to 3 and remove elements after that\n",
    "my_list[1:] = [0, 9, 8]\n",
    "# print list\n",
    "print(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616011ef",
   "metadata": {},
   "source": [
    "<a name=\"Strings\"></a>\n",
    "### 2.3 Strings\n",
    "**Indexing**, **slicing** and **concatenation** works the same in strings as in lists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28528a4c",
   "metadata": {},
   "source": [
    "We can **join two words into a single string** with a specified delimiter.\n",
    "\n",
    "**Syntax**: `\"delimiter\".join([word1, word2])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34c0cbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moby-Dick\n"
     ]
    }
   ],
   "source": [
    "# join the two strings with \"-\" as the delimiter and assign it to a variable\n",
    "moby_dick = \"-\".join([\"Moby\", \"Dick\"])\n",
    "print(moby_dick)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3324b2",
   "metadata": {},
   "source": [
    "We can **tokenize** a text, i.e. **split the text into individual words** with a specified delimiter.\n",
    "\n",
    "**Syntax**: `text.split(\"delimiter\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "58b0d821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Moby', 'Dick']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the phrase into individual words with '-' as the delimiter\n",
    "moby_dick.split(\"-\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
