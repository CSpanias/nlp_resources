{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f2dec07",
   "metadata": {},
   "source": [
    "# **Natural Language Processing with Python**\n",
    "by [CSpanias](https://cspanias.github.io/aboutme/) - 01/2022\n",
    "\n",
    "Content based on the [NLTK book](https://www.nltk.org/book/). <br>\n",
    "\n",
    "You can find Chapter 3 [here](https://www.nltk.org/book/ch03.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0276129",
   "metadata": {},
   "source": [
    "**1\\.** Define a string `s = 'colorless'`. Write a Python statement that changes this to `'colourless'` using only the **slice** and **concatenation** operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0768b919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'colourless'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define string\n",
    "s = 'colorless'\n",
    "\n",
    "# slice first 4 letters of s\n",
    "# concatenate letter 'u'\n",
    "# concatenate last 4 letters of s\n",
    "s[:4] + 'u' + s[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331974ea",
   "metadata": {},
   "source": [
    "**2\\.** We can use the slice notation to remove morphological endings on words.\n",
    "\n",
    "For example, `'dogs'[:-1]` removes the last characters of `'dogs'`, leaving `'dog'`. \n",
    "\n",
    "Use **slice notation** to remove the affixes from these words (we 've inserted a hyphen to indicate the affix boundary, but omit this from your strings): _dish-es, run-ning, nation-ality, un-do, pre-heat._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6456044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dish', 'run', 'nation', 'un', 'pre')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define strings\n",
    "s1, s2, s3, s4, s5 = 'dishes', 'running', 'nationality', 'undo', 'preheat'\n",
    "\n",
    "# remove affixes using slice notation\n",
    "s1[:-2], s2[:-4], s3[:-5], s4[:-2], s5[:-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b568ca",
   "metadata": {},
   "source": [
    "**3\\.** We saw how we can generate an `IndexError` by indexing beyond the end of a string. \n",
    "\n",
    "Is it possible to **construct an index that goes too far to the left, before the start of the string**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64a8a591",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10016/4213648208.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# an index to go to far to the left\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "# define a string\n",
    "s = 'dog'\n",
    "\n",
    "# an index that goes to far to the left\n",
    "s[-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0002b62",
   "metadata": {},
   "source": [
    "**4\\.** We can specify a **\"step\" size** for the slice. \n",
    "\n",
    "The following returns every second character withinthe slice: `monty[6:11:2]`. \n",
    "\n",
    "It also works in the reverse direction: `monty[10:5:-2]`.\n",
    "\n",
    "Try these for yourself, then experiment with different step values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7706d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apn\n",
      "arln\n",
      "eapi\n"
     ]
    }
   ],
   "source": [
    "# define a string\n",
    "s = 'airplane'\n",
    "\n",
    "# return every 3rd character inside the slice range\n",
    "print(s[0:7:3])\n",
    "\n",
    "# return every 2rd character inside the slice range\n",
    "print(s[0:7:2])\n",
    "\n",
    "# return every 2rd character inside the slice range in reverse\n",
    "print(s[7:0:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96710cd0",
   "metadata": {},
   "source": [
    "**5\\.** What happens if you ask the interpreter to evaluate `monty[::-1]`?\n",
    "\n",
    "Explain why this is a reasonable result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac08b3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ytnom'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try slice & step size\n",
    "'monty'[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361890f6",
   "metadata": {},
   "source": [
    "The slice returns the **word in reverse**. \n",
    "\n",
    "That is the expected result as the slice `[::]` indicates that is goes **through the whole range** of the word. \n",
    "\n",
    "The addition of `[::-1]` indicates that it **starts from the end with a step size of 1**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befc52d8",
   "metadata": {},
   "source": [
    "**6\\.** Describe the **class of strings matched** by the following regular expressions.\n",
    "\n",
    "`[a-zA-Z]+` one or more lower- or upper-case alphabetic character(s)\n",
    "\n",
    "`[A-Z][a-z]*` a sequence of two characters 0 or more times: an upper-case alphabetic & a lower-case alphabetic.\n",
    "\n",
    "`p[aeiou]{,2}t` the letter 'p', any lower-case vowel from 0 to 2 times, and the letter 't'.\n",
    "\n",
    "`\\d+(\\.\\d+)?` one or more digit(s), and optionally extract only a dot & one or more digit(s).\n",
    "\n",
    "`([^aeiou][aeiou][^aeiou])*` extract a word sequence 3 characters long for 0 or more times that: starts with anything but a vowel, followed by a vowel & ends with anything but vowel.\n",
    "\n",
    "`\\w+|[^\\w\\s]+` one or more alphabetic character(s) or a word that starts with anything than an alphabetic character or a whitespace for one or more times.\n",
    "\n",
    "Test your answers using `nltk.re_show()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fad88d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{Daniel} {Lambert} {was} {born} {on} {the} 13 {of} {March}, 1770,\n",
      "None \n",
      "\n",
      "\n",
      "{Daniel} {Lambert} was born on the 13 of {March}, 1770,\n",
      "None \n",
      "\n",
      "\n",
      "Daniel Lambert was born on the 13 of March, 1770, in the Parish of\n",
      "St. Margaret, at Leicester. From the extraordinary bulk to which he\n",
      "attained, the reader may be naturally disposed to inquire, whether or\n",
      "no his parents were persons of remarkable dimensions. This was not the\n",
      "case; nor were any of his family inclined to corpulence, exce{pt}ing\n",
      "an unc\n",
      "None \n",
      "\n",
      "\n",
      "Daniel Lambert was born on the {13} of March, {1770},\n",
      "None \n",
      "\n",
      "{}\n",
      "{Dan}{}i{}e{}l{} {Lamber}{}t{} {was}{} {bor}{}n{ on}{} {}t{he }{}1{}3{ of}{} {Mar}{}c{}h{},{} {}1{}7{}7{}0{},{}\n",
      "None \n",
      "\n",
      "\n",
      "{Daniel} {Lambert} {was} {born} {on} {the} {13} {of} {March}{,} {1770}{,}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\"\n",
    "Daniel Lambert was born on the 13 of March, 1770, in the Parish of\n",
    "St. Margaret, at Leicester. From the extraordinary bulk to which he\n",
    "attained, the reader may be naturally disposed to inquire, whether or\n",
    "no his parents were persons of remarkable dimensions. This was not the\n",
    "case; nor were any of his family inclined to corpulence, excepting\n",
    "an uncle and aunt on the father’s side, who were both very heavy.\n",
    "The former died during the infancy of Lambert, in the capacity of\n",
    "gamekeeper to the Earl of Stamford, to whose predecessor his father had\n",
    "been huntsman in early life. The family of Lambert, senior, consisted\n",
    "besides Daniel, of another son, who died young, and two daughters, who\n",
    "are still living, and both women of the common size.\n",
    "\n",
    "The habits of the subject, 34*1+10 of this memoir were not, in any respect,\n",
    "different from those of other young persons till the age of fourteen.\n",
    "Even at that early period he was strongly attached to the sports of the\n",
    "field. This, however, was only the natural effect of a very obvious\n",
    "cause, aided probably by an innate propensity to those diversions.--We\n",
    "have already mentioned the profession of his father and uncle, and have\n",
    "yet to observe, that his maternal grandfather was a great cock-fighter.\n",
    "Born and bred among horses, dogs, and cocks, and all the other\n",
    "appendages of sporting, in the pursuits of which he was encouraged\n",
    "even in his childhood, it cannot be a matter of wonder that he should\n",
    "be passionately fond of all those exercises and amusements, which are\n",
    "comprehended under the denomination of field sports. 12+34*1\n",
    "\"\"\"\n",
    "print(nltk.re_show(r'[a-zA-Z]+', s[:50]), \"\\n\")\n",
    "print(nltk.re_show(r'[A-Z][a-z]*', s[:50]), \"\\n\")\n",
    "print(nltk.re_show(r'p[aeiou]{,2}t', s[:350]), \"\\n\")\n",
    "print(nltk.re_show(r'\\d+(\\.\\d+)?', s[:50]), \"\\n\")\n",
    "print(nltk.re_show(r'([^aeiou][aeiou][^aeiou])*', s[:50]), \"\\n\")\n",
    "print(nltk.re_show(r'\\w+|[^\\w\\s]+', s[:50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db13f876",
   "metadata": {},
   "source": [
    "**7\\.** Write **regular expressions** to match the following classes of strings:\n",
    "\n",
    "1. A single determiner (assume that _a, an,_ and _the_ are the only determiners).\n",
    "2. An arithmetic expression using integers, addition, and multiplication, such as 2*3+8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "87f569e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Daniel Lambert was born on {the }13 of March, 1770, in {the }Parish of\n",
      "St. Margaret, at Leicester. From {the }extraordinary bulk to which he\n",
      "attained, {the }reader may be naturally disposed to inquire, whether or\n",
      "no his parents were persons of remarkable dimensions. This was not {the\n",
      "}case; nor were any of his family inclined to corpulence, excepting\n",
      "{an }uncle and aunt on {the }father’s side, who were both very heavy.\n",
      "The former died during {the }infancy of Lambert, in {the }capacity of\n",
      "gamekeeper to {the }Earl of Stamford, to whose predecessor his father had\n",
      "been huntsm{an }in early life. The family of Lambert, senior, consisted\n",
      "besides Daniel, of another son, who died young, and two daughters, who\n",
      "are still living, and both women of {the }common size.\n",
      "\n",
      "The habits of {the }subject, 34*1+10 of this memoir were not, in any respect,\n",
      "different from those of other young persons till {the }age of fourteen.\n",
      "Even at that early period he was strongly attached to {the }sports of {the\n",
      "}field. This, however, was only {the }natural effect of {a }very obvious\n",
      "cause, aided probably by {an }innate propensity to those diversions.--We\n",
      "have already mentioned {the }profession of his father and uncle, and have\n",
      "yet to observe, that his maternal grandfather was {a }great cock-fighter.\n",
      "Born and bred among horses, dogs, and cocks, and all {the }other\n",
      "appendages of sporting, in {the }pursuits of which he was encouraged\n",
      "even in his childhood, it cannot be {a }matter of wonder that he should\n",
      "be passionately fond of all those exercises and amusements, which are\n",
      "comprehended under {the }denomination of field sports. 12+34*1\n",
      "\n",
      "Daniel Lambert was born on the 13 of March, 1770, in the Parish of\n",
      "St. Margaret, at Leicester. From the extraordinary bulk to which he\n",
      "attained, the reader may be naturally disposed to inquire, whether or\n",
      "no his parents were persons of remarkable dimensions. This was not the\n",
      "case; nor were any of his family inclined to corpulence, excepting\n",
      "an uncle and aunt on the father’s side, who were both very heavy.\n",
      "The former died during the infancy of Lambert, in the capacity of\n",
      "gamekeeper to the Earl of Stamford, to whose predecessor his father had\n",
      "been huntsman in early life. The family of Lambert, senior, consisted\n",
      "besides Daniel, of another son, who died young, and two daughters, who\n",
      "are still living, and both women of the common size.\n",
      "\n",
      "The habits of the subject, 34*1+10 of this memoir were not, in any respect,\n",
      "different from those of other young persons till the age of fourteen.\n",
      "Even at that early period he was strongly attached to the sports of the\n",
      "field. This, however, was only the natural effect of a very obvious\n",
      "cause, aided probably by an innate propensity to those diversions.--We\n",
      "have already mentioned the profession of his father and uncle, and have\n",
      "yet to observe, that his maternal grandfather was a great cock-fighter.\n",
      "Born and bred among horses, dogs, and cocks, and all the other\n",
      "appendages of sporting, in the pursuits of which he was encouraged\n",
      "even in his childhood, it cannot be a matter of wonder that he should\n",
      "be passionately fond of all those exercises and amusements, which are\n",
      "comprehended under the denomination of field sports. 12+34*1\n"
     ]
    }
   ],
   "source": [
    "# determiner\n",
    "nltk.re_show(r'(a\\s|an\\s|the\\s)', s)\n",
    "\n",
    "# arithmetic expression\n",
    "nltk.re_show(r'^\\d+[\\*\\+]\\d+[\\*\\+]d+$', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf9c7a2",
   "metadata": {},
   "source": [
    "**8\\.** Write a **utility function** that takes a URL as its argument, and returns the contents of the URL, with **all HTML markup removed**. \n",
    "\n",
    "Use `from urllib import request` and then `request.urlopen('http://nltk.org/').read().decode('utf8')` to access the contents of the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "411ce11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first 100 characters of the original URL contents:\n",
      "\n",
      "<!DOCTYPE html>\n",
      "<head>\n",
      "  <meta chars\n",
      "This is the first 100 characters with stripped HTML markup:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NLTK :: Natural Language Toolkit\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NLTK\n",
      "\n",
      "\n",
      "\n",
      "Documentation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NLTK Docume\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def remove_HTML(url):\n",
    "    \"\"\"Remove HTML markup from text.\"\"\"\n",
    "    \n",
    "    # access contents\n",
    "    content = request.urlopen(url).read().decode('utf8')\n",
    "    # strip text from HTML markup\n",
    "    raw = BeautifulSoup(content, 'html.parser').get_text()\n",
    "    \n",
    "    # return stripped text\n",
    "    return raw\n",
    "\n",
    "# define URL\n",
    "url_address = 'http://nltk.org/'\n",
    "\n",
    "# check original content\n",
    "print(\"This is the first 100 characters of the original URL contents:\\n\\n{}\\n\".\n",
    "     format(request.urlopen(url_address).read().decode('utf8'))[:100])\n",
    "\n",
    "# invoke function\n",
    "print(\"This is the first 100 characters with stripped HTML markup:\\n\\n{}\".\n",
    "      format(remove_HTML(url_address)[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be154e2e",
   "metadata": {},
   "source": [
    "**9\\.** Save some text into a file `corpus.txt`.\n",
    "\n",
    "Define a function `load(f)` that reads from the file named in its sole argument, and returns a string containing the text of the file.\n",
    "\n",
    "1. Use `nltk.regexp_tokenize()` to create a tokenizer that tokenizes the various kinds of punctuation in this text. Use one multi-line regular expression, with inline comments, using the verbose flag `(?x)`.\n",
    "2. Use `nltk.regexp_tokenize()` to create a tokenizer that tokenizes the following kinds of expression: monetary amounts; dates; names of people and organizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e095315f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file's content is the following:\n",
      "\n",
      "This is the file's text. My name is Mike, today is 10-02-2022 and I have £0.00 on my account. I work in Unemployment Org. I also have 0.000$ !\n",
      "\n",
      "Tokenized text without punctuation marks:\n",
      "\n",
      "['This ', 'is ', 'the ', 's ', ' ', 'My ', 'name ', 'is ', ' ', 'today ', 'is ', '2022 ', 'and ', 'I ', 'have ', '00 ', 'on ', 'my ', ' ', 'I ', 'work ', 'in ', 'Unemployment ', ' ', 'I ', 'also ', 'have ', ' ']\n",
      "\n",
      "Tokenized text with 2nd pattern:\n",
      "\n",
      "['This', 'My', 'Mike', '10-02-2022', '£0.00', 'Unemployment', 'Org', '0.000$']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a file & write some text\n",
    "with open('corpus.txt', 'w') as f:\n",
    "    f.write('This is the file\\'s text. My name is Mike, '\n",
    "            'today is 10-02-2022 and I have £0.00 on my account. '\n",
    "            'I work in Unemployment Org. I also have 0.000$ !')\n",
    "    \n",
    "# define function\n",
    "def load(f):\n",
    "    \"\"\"Read a file and return the text of that file.\"\"\"\n",
    "    # open the file\n",
    "    with open(f) as f:\n",
    "        # save its content\n",
    "        content = f.read()\n",
    "    # return content\n",
    "    return content\n",
    "\n",
    "# read content's file\n",
    "print(\"The file's content is the following:\\n\\n{}\\n\".\n",
    "      format(load('corpus.txt')))\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# assign text to var\n",
    "my_text = load('corpus.txt')\n",
    "\n",
    "# create multi-line regex pattern\n",
    "pattern = r'''(?x)         # verbose flag\n",
    "        (\\w*\\d*\\s)         # extract words, digits, whitespace\n",
    "'''\n",
    "\n",
    "# instantiate Regexp tokenizer\n",
    "tokenizer = RegexpTokenizer(pattern)\n",
    "\n",
    "# tokenize text\n",
    "tokens = tokenizer.tokenize(my_text)\n",
    "\n",
    "# check results\n",
    "print(\"Tokenized text without punctuation marks:\\n\\n{}\\n\".\n",
    "      format(tokens))\n",
    "\n",
    "pattern_B = r'''(?x)         # verbose flag\n",
    "\n",
    "        \\d{,2}-\\d{2}-\\d{4}   # dates\n",
    "    |   \\£?\\d+(?:\\.\\d+)?\\$?  # monetary amounts\n",
    "    |   [A-Z]\\w+             # proper names\n",
    "'''\n",
    "\n",
    "# instantiate Regexp tokenizer\n",
    "tokenizer_B = RegexpTokenizer(pattern_B)\n",
    "\n",
    "# tokenize text\n",
    "tokens_b = tokenizer_B.tokenize(my_text)\n",
    "\n",
    "# check results\n",
    "print(\"Tokenized text with 2nd pattern:\\n\\n{}\\n\".\n",
    "      format(tokens_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4716057e",
   "metadata": {},
   "source": [
    "**10\\.** Rewrite the following loop as a list comprehension:\n",
    "\n",
    "`sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "result = []\n",
    "for word in sent:\n",
    "    word_len = (word, len(word))\n",
    "    result.append(word_len)\n",
    "result`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ac645b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 3),\n",
       " ('dog', 3),\n",
       " ('gave', 4),\n",
       " ('John', 4),\n",
       " ('the', 3),\n",
       " ('newspaper', 9)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "\n",
    "# list comprehension\n",
    "result = [(word, len(word)) for word in sent]\n",
    "\n",
    "# check result\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bbfcf9",
   "metadata": {},
   "source": [
    "**11\\.** Define a string `raw` containing a sentence of your own choosing.\n",
    "\n",
    "Now, split `raw` on some character other than space, such as `'s'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3d6c970a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thi', ' i', ' my amazing and imaginative ', 'tring!']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define string\n",
    "raw = 'This is my amazing and imaginative string!'\n",
    "\n",
    "# split string\n",
    "raw.split('s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1563d",
   "metadata": {},
   "source": [
    "**12\\.** Write a `for` loop to print out the characters for a string, one per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fc0c90ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m\n",
      "y\n",
      " \n",
      "s\n",
      "t\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "# define string \n",
    "s = 'my string!'\n",
    "\n",
    "# print characters one per line\n",
    "for char in s:\n",
    "    print(char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa394cc3",
   "metadata": {},
   "source": [
    "**13\\.** What is the difference between calling `split` on a string with no argument or with `' '` as the argument, e.g. `sent.split()` versus `sent.split(' ')`?\n",
    "\n",
    "What happens when the string being split contains tab characters, consecutive space characters, or a sequence of tabs and spaces?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "55e89b87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the result of '.split()':\n",
      "\n",
      "['This', 'is', 'my', 'amazing', 'and', 'imaginative', 'string!']\n",
      "\n",
      "This is the result of '.split(' ')':\n",
      "\n",
      "['This', 'is', 'my', 'amazing', 'and', 'imaginative', 'string!']\n",
      "\n",
      "This is the result of '.split()' with extra whitespace:\n",
      "\n",
      "['This', 'is', 'my', 'amazing', 'and', 'imaginative', 'string!']\n",
      "\n",
      "This is the result of '.split(' ')' with extra whitespace:\n",
      "\n",
      "['This', 'is', '', '', '', 'my', 'amazing', 'and', '', '', '', 'imaginative', 'string!']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define a string\n",
    "raw = 'This is my amazing and imaginative string!'\n",
    "\n",
    "# split string\n",
    "print(\"This is the result of '.split()':\\n\\n{}\\n\".format(raw.split()))\n",
    "\n",
    "print(\"This is the result of '.split(' ')':\\n\\n{}\\n\".format(raw.split(' ')))\n",
    "\n",
    "\n",
    "# define a string\n",
    "raw_extrawhitespace = 'This is    my amazing and    imaginative string!'\n",
    "\n",
    "# split string\n",
    "print(\"This is the result of '.split()' with extra whitespace:\\n\\n{}\\n\".format(raw_extrawhitespace.split()))\n",
    "\n",
    "print(\"This is the result of '.split(' ')' with extra whitespace:\\n\\n{}\\n\".format(raw_extrawhitespace.split(' ')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec61422",
   "metadata": {},
   "source": [
    "When there are **no tabs, consecutive space characters, or a sequence of tabs and spaces** there is no difference between `.split()` and `split(' ')`. \n",
    "\n",
    "When there are **tabs, consecutive space characters, or a sequence of tabs and spaces** it splits on the first white space it encounters and prints the rest as characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232da76d",
   "metadata": {},
   "source": [
    "**14\\.** Create a variable `words` containing a list of words. Experiment with `words.sort()` and `sorted(words)`. \n",
    "\n",
    "What is the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b906ae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the result of `words.sort()`:\n",
      "\n",
      "None\n",
      "\n",
      "This is the result of `.sorted(words)`:\n",
      "\n",
      "['word1', 'word2', 'word3', 'word4', 'word5']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = ['word1', 'word3', 'word2', 'word5', 'word4']\n",
    "\n",
    "# try difference sorting methods\n",
    "print(\"This is the result of `words.sort()`:\\n\\n{}\\n\".format(words.sort()))\n",
    "\n",
    "print(\"This is the result of `.sorted(words)`:\\n\\n{}\\n\".format(sorted(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a3a762",
   "metadata": {},
   "source": [
    "`.sort()` returns `None`; it modifies the original list on the spot.\n",
    "\n",
    "`sorted()` returns the list sorted; it does not affect the original list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0dc5d",
   "metadata": {},
   "source": [
    "**15\\.** Explore the difference between strings and integers by typing the following at a Python prompt: `\"3\" * 7` and `3 * 7`.\n",
    "\n",
    "Try converting between strings and integers using `int(\"3\")` and `str(3)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "539beadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the result of '3' * 7: 3333333 and its data type is: <class 'str'>.\n",
      "\n",
      "This is the result of 3 * 7: 21 and its data type is: <class 'int'>.\n",
      "\n",
      "This is the result of int(str_mult): 3333333 and its data type is: <class 'int'>.\n",
      "\n",
      "This is the result of str(num_mult): 21 and its data type is: <class 'str'>.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check differences\n",
    "str_mult = \"3\" * 7\n",
    "print(\"This is the result of '3' * 7: {} and its data type is: {}.\\n\".\n",
    "      format((str_mult), type(str_mult)))\n",
    "\n",
    "num_mult = 3 * 7\n",
    "print(\"This is the result of 3 * 7: {} and its data type is: {}.\\n\".\n",
    "      format((num_mult), type(num_mult)))\n",
    "\n",
    "# try convertions\n",
    "print(\"This is the result of int(str_mult): {} and its data type is: {}.\\n\".\n",
    "      format(int(str_mult), type(int(str_mult))))\n",
    "\n",
    "print(\"This is the result of str(num_mult): {} and its data type is: {}.\\n\".\n",
    "      format(str(num_mult), type(str(num_mult))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
