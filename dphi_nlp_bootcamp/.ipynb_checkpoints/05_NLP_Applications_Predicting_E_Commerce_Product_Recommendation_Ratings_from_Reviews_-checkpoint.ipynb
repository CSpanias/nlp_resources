{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8wgGEuy-9G1x"
   },
   "source": [
    "# Predicting E-Commerce Product Recommendation Ratings from Reviews \n",
    "\n",
    "\n",
    "![](https://github.com/dipanjanS/feature_engineering_session_dhs18/blob/master/ecommerce_product_ratings_prediction/clothing_banner.jpg?raw=1)\n",
    "\n",
    "This is a classic NLP problem dealing with data from an e-commerce store focusing on women's clothing. Each record in the dataset is a customer review which consists of the review title, text description and a rating (ranging from 1 - 5) for a product amongst other features\n",
    "\n",
    "We convert this into a binary classification problem such that a customer recommends a product (label 1) is the rating is > 3 else they do not recommend the product (label 0)\n",
    "\n",
    "__Main Objective:__ Leverage the review text attributes to predict the recommendation rating (classification)\n",
    "\n",
    "\n",
    "_Author: Dipanjan (DJ) Sarkar_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NdpvzY1D9G1y"
   },
   "source": [
    "# Load up basic dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VXs4584w9G1y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PxMJ0XnP9G11"
   },
   "source": [
    "# Load and View the Dataset\n",
    "\n",
    "The data is available at https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews from where you can download it.\n",
    "\n",
    "\n",
    "We recommend using the kaggle API and the following command via CLI to get it.\n",
    "\n",
    "__`kaggle datasets download -d nicapotato/womens-ecommerce-clothing-reviews`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "xmq8n6Sa9G12",
    "outputId": "77cb6a72-43ae-4df4-81bb-d26822e8c2f4",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td></td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td></td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age  ...   Division Name Department Name  Class Name\n",
       "0           0          767   33  ...       Initmates        Intimate   Intimates\n",
       "1           1         1080   34  ...         General         Dresses     Dresses\n",
       "2           2         1077   60  ...         General         Dresses     Dresses\n",
       "3           3         1049   50  ...  General Petite         Bottoms       Pants\n",
       "4           4          847   47  ...         General            Tops     Blouses\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/dipanjanS/feature_engineering_session_dhs18/master/ecommerce_product_ratings_prediction/Womens%20Clothing%20E-Commerce%20Reviews.csv', keep_default_na=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSWdX9p49G15"
   },
   "source": [
    "# Basic Data Processing\n",
    "\n",
    "- Merge all review text attributes (title, text description) into one attribute\n",
    "- Convert the 5-star rating system into a binary recommendation rating of 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "wD3desQl9G16",
    "outputId": "5788af75-820a-4c13-b580-1ba106f5d172"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Some major design flaws I had such high hopes ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My favorite buy! I love, love, love this jumps...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flattering shirt This shirt is very flattering...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  Absolutely wonderful - silky and sexy and comf...       1\n",
       "1  Love this dress!  it's sooo pretty.  i happene...       1\n",
       "2  Some major design flaws I had such high hopes ...       0\n",
       "3  My favorite buy! I love, love, love this jumps...       1\n",
       "4  Flattering shirt This shirt is very flattering...       1"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review'] = (df['Title'].map(str) +' '+ df['Review Text']).apply(lambda row: row.strip())\n",
    "df['Rating'] = [1 if rating > 3 else 0 for rating in df['Rating']]\n",
    "df = df[['Review', 'Rating']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hWM1huGb9G19"
   },
   "source": [
    "## Remove all records with no review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "VB2DhPLH9G19",
    "outputId": "0c8fcc37-0998-435e-a912-f6f60f9c30de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22642 entries, 0 to 23485\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  22642 non-null  object\n",
      " 1   Rating  22642 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 530.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df[df['Review'] != '']\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sa8SCfu59G1_"
   },
   "source": [
    "## There is some imbalance in the data based on product ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "LHRcOkxZ9G2A",
    "outputId": "fdeea29a-c6ab-4634-848d-83cd9a4df54e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17449\n",
       "0     5193\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9HZhCnN9G2C"
   },
   "source": [
    "# Build train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jBsPt1rC9G2C",
    "outputId": "047e7192-a598-47c1-d0e2-25a38fd8ba14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16981, 1), (5661, 1))"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['Review']], df['Rating'], random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_m6_wP6X9G2F",
    "outputId": "b703f0af-1d6c-4200-b494-e37be4a59411"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 3922, 1: 13059}), Counter({0: 1271, 1: 4390}))"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train), Counter(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZiKBkmzA9G2H"
   },
   "source": [
    "# Experiment 1: Basic NLP Count based Features\n",
    "\n",
    "A number of basic text based features can also be created which sometimes are helpful for improving text classification models. \n",
    "Some examples are:\n",
    "\n",
    "- __Word Count:__ total number of words in the documents\n",
    "- __Character Count:__ total number of characters in the documents\n",
    "- __Average Word Density:__ average length of the words used in the documents\n",
    "- __Puncutation Count:__ total number of punctuation marks in the documents\n",
    "- __Upper Case Count:__ total number of upper count words in the documents\n",
    "- __Title Word Count:__ total number of proper case (title) words in the documents\n",
    "\n",
    "Source: https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rk6Kc62u9G2H"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "X_train['char_count'] = X_train['Review'].apply(len)\n",
    "X_train['word_count'] = X_train['Review'].apply(lambda x: len(x.split()))\n",
    "X_train['word_density'] = X_train['char_count'] / (X_train['word_count']+1)\n",
    "X_train['punctuation_count'] = X_train['Review'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "X_train['title_word_count'] = X_train['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "X_train['upper_case_word_count'] = X_train['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
    "\n",
    "\n",
    "X_test['char_count'] = X_test['Review'].apply(len)\n",
    "X_test['word_count'] = X_test['Review'].apply(lambda x: len(x.split()))\n",
    "X_test['word_density'] = X_test['char_count'] / (X_test['word_count']+1)\n",
    "X_test['punctuation_count'] = X_test['Review'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "X_test['title_word_count'] = X_test['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "X_test['upper_case_word_count'] = X_test['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "iyJ87jSe9G2J",
    "outputId": "47cce8ab-5da8-49f3-929e-01d225864d79"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12896</th>\n",
       "      <td>Soooo soft! This is a delightfully soft and fl...</td>\n",
       "      <td>268</td>\n",
       "      <td>52</td>\n",
       "      <td>5.056604</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13183</th>\n",
       "      <td>Had my eye on this, but dind't get I finally v...</td>\n",
       "      <td>399</td>\n",
       "      <td>84</td>\n",
       "      <td>4.694118</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>I wanted to like this... I wanted to like this...</td>\n",
       "      <td>525</td>\n",
       "      <td>104</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5205</th>\n",
       "      <td>Beautiful blouse Bought this for my daughter i...</td>\n",
       "      <td>203</td>\n",
       "      <td>35</td>\n",
       "      <td>5.638889</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13366</th>\n",
       "      <td>Boxy. large. Boxy, unflattering, and large.\\n\\...</td>\n",
       "      <td>295</td>\n",
       "      <td>51</td>\n",
       "      <td>5.673077</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  ...  upper_case_word_count\n",
       "12896  Soooo soft! This is a delightfully soft and fl...  ...                      0\n",
       "13183  Had my eye on this, but dind't get I finally v...  ...                      1\n",
       "1496   I wanted to like this... I wanted to like this...  ...                      2\n",
       "5205   Beautiful blouse Bought this for my daughter i...  ...                      0\n",
       "13366  Boxy. large. Boxy, unflattering, and large.\\n\\...  ...                      0\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1mHfxYqj9G2L"
   },
   "source": [
    "## Training a Logistic Regression Model \n",
    "\n",
    "A logistic regression model is easy to train, interpret and works well on a wide variety of NLP problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xlxi2zO9G2L"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=1, random_state=42, solver='liblinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yLi8rI2d9G2N"
   },
   "source": [
    "## Model Evaluation Metrics - Quick Refresher\n",
    "\n",
    "Just accuracy is never enough in datasets with a rare class problem.\n",
    "\n",
    "- __Precision:__ The positive predictive power of a model. Out of all the predictions made by a model for a class, how many are actually correct\n",
    "- __Recall:__ The coverage or hit-rate of a model. Out of all the test data samples belonging to a class, how many was the model able to predict (hit or cover) correctly.\n",
    "- __F1-score:__ The harmonic mean of the precision and recall\n",
    "\n",
    "Do check out ROC Curve, AUC Score and PR Curve also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "v7uniDrC9G2O",
    "outputId": "549e2638-58b9-4360-fe88-9f8e2b1a0904"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1271\n",
      "           1       0.78      1.00      0.87      4390\n",
      "\n",
      "    accuracy                           0.78      5661\n",
      "   macro avg       0.39      0.50      0.44      5661\n",
      "weighted avg       0.60      0.78      0.68      5661\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1\n",
       "0  0  1271\n",
       "1  0  4390"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train.drop(['Review'], axis=1), y_train)\n",
    "predictions = lr.predict(X_test.drop(['Review'], axis=1))\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "pd.DataFrame(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WB1WXnmS9G2Q"
   },
   "source": [
    "Looks like our model was not able to predict a single product having a bad (no recommendation) rating, i.e. __Class 0__. \n",
    "\n",
    "This is as good as someone predicting a __1__ or __good__ for every product review. \n",
    "\n",
    "Can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Njk5U6ld9G2a"
   },
   "source": [
    "# Leveraging Text Sentiment\n",
    "\n",
    "Reviews are pretty subjective, opinionated and people often express stong emotions, feelings. \n",
    "This makes it a classic case where the text documents here are a good candidate for extracting sentiment as a feature.\n",
    "\n",
    "The general expectation is that highly rated and recommended products (__label 1__) should have a __positive__ sentiment and products which are not recommended (__label 0__) should have a __negative__ sentiment.\n",
    "\n",
    "TextBlob is an excellent open-source library for performing NLP tasks with ease, including sentiment analysis. It also an a sentiment lexicon (in the form of an XML file) which it leverages to give both polarity and subjectivity scores. \n",
    "\n",
    "- The polarity score is a float within the range [-1.0, 1.0]. \n",
    "- The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective. \n",
    "\n",
    "Perhaps this could be used for getting some new features? Let's look at some basic examples.\n",
    "\n",
    "Source: https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oG7_MSsR9G2a",
    "outputId": "20f440ec-31e1-4d41-e276-2824b4348725"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.7500000000000001, subjectivity=0.9)"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textblob\n",
    "\n",
    "textblob.TextBlob('This is an AMAZING pair of Jeans!').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "71olVhAp9G2d",
    "outputId": "64b444d4-5e38-4474-fb4f-64826107da49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.95, subjectivity=0.85)"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblob.TextBlob('I really hated this UGLY T-shirt!!').sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G9vlglD09G2f"
   },
   "source": [
    "Looks like this should help us get features which can distinguish between good and bad products. Let's try it out on our dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k1D5kDCM9G2f"
   },
   "source": [
    "# Experiment 2: Features from Sentiment Analysis \n",
    "\n",
    "Remember this is unsupervised, lexicon-based sentiment analysis where we don't have any pre-labeled data saying which review migth have a positive or negative sentiment. We use the lexicon to determine this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkYd9_8A9G2f"
   },
   "outputs": [],
   "source": [
    "x_train_snt_obj = X_train['Review'].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
    "X_train['Polarity'] = [obj.polarity for obj in x_train_snt_obj.values]\n",
    "X_train['Subjectivity'] = [obj.subjectivity for obj in x_train_snt_obj.values]\n",
    "\n",
    "x_test_snt_obj = X_test['Review'].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
    "X_test['Polarity'] = [obj.polarity for obj in x_test_snt_obj.values]\n",
    "X_test['Subjectivity'] = [obj.subjectivity for obj in x_test_snt_obj.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "5so7o_W89G2h",
    "outputId": "57bb8e33-8416-4d78-8b3c-734aaf106dae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12896</th>\n",
       "      <td>Soooo soft! This is a delightfully soft and fl...</td>\n",
       "      <td>268</td>\n",
       "      <td>52</td>\n",
       "      <td>5.056604</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.490909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13183</th>\n",
       "      <td>Had my eye on this, but dind't get I finally v...</td>\n",
       "      <td>399</td>\n",
       "      <td>84</td>\n",
       "      <td>4.694118</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101944</td>\n",
       "      <td>0.719537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>I wanted to like this... I wanted to like this...</td>\n",
       "      <td>525</td>\n",
       "      <td>104</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.186538</td>\n",
       "      <td>0.458761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5205</th>\n",
       "      <td>Beautiful blouse Bought this for my daughter i...</td>\n",
       "      <td>203</td>\n",
       "      <td>35</td>\n",
       "      <td>5.638889</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13366</th>\n",
       "      <td>Boxy. large. Boxy, unflattering, and large.\\n\\...</td>\n",
       "      <td>295</td>\n",
       "      <td>51</td>\n",
       "      <td>5.673077</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329613</td>\n",
       "      <td>0.510268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  ...  Subjectivity\n",
       "12896  Soooo soft! This is a delightfully soft and fl...  ...      0.490909\n",
       "13183  Had my eye on this, but dind't get I finally v...  ...      0.719537\n",
       "1496   I wanted to like this... I wanted to like this...  ...      0.458761\n",
       "5205   Beautiful blouse Bought this for my daughter i...  ...      0.825000\n",
       "13366  Boxy. large. Boxy, unflattering, and large.\\n\\...  ...      0.510268\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G7xf9V_59G2j"
   },
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "_fiZszFw9G2j",
    "outputId": "7ddabd2f-c990-46a9-a332-6dca46f3e917"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.27      0.38      1271\n",
      "           1       0.82      0.97      0.89      4390\n",
      "\n",
      "    accuracy                           0.81      5661\n",
      "   macro avg       0.75      0.62      0.64      5661\n",
      "weighted avg       0.79      0.81      0.77      5661\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>339</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153</td>\n",
       "      <td>4237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1\n",
       "0  339   932\n",
       "1  153  4237"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train.drop(['Review'], axis=1), y_train, )\n",
    "predictions = lr.predict(X_test.drop(['Review'], axis=1))\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "pd.DataFrame(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0mx9hX449G2l"
   },
   "source": [
    "Interesting! Looks like we are now able to predict __27%__ of the total number of bad or negative rated products now! \n",
    "Precision is quite good at __69%__\n",
    "\n",
    "__F1-Score__ for bad reviews is now __40%__ and good reviews is __89%__\n",
    "\n",
    "This brings our overall __F1-Score__ to __77%__ which is quite good.\n",
    "\n",
    "Can we still improve on our model since the recall of bad reviews is still pretty low?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U09f6e829G2l"
   },
   "source": [
    "# Text Pre-processing and Wrangling\n",
    "\n",
    "We want to extract some specific features based on standard NLP feature engineering models like the classic Bag of Words model.\n",
    "For this we need to clean and pre-process our text data. We will build a simple text pre-processor here since the main intent is to look at feature engineering strategies.\n",
    "\n",
    "We will focus on:\n",
    "- Text Lowercasing\n",
    "- Removal of contractions\n",
    "- Removing unnecessary characters, numbers and symbols\n",
    "- Stemming\n",
    "- Stopword removal\n",
    "\n",
    "Source: https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "RNNjrbiRAXpA",
    "outputId": "a1a4b6dd-5381-4023-e7f4-19352e329ddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.25)\n",
      "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (from contractions) (0.0.17)\n",
      "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.4.0)\n",
      "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.1.1)\n",
      "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (0.0.17)\n",
      "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch) (1.4.0)\n",
      "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch) (1.1.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install contractions\n",
    "!pip install textsearch\n",
    "!pip install tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "s8PQYYWm9G2n",
    "outputId": "32ae4c28-d3c2-414f-9ffb-2bc21ec0d2b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I did not like this t-shirt'"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import contractions\n",
    "\n",
    "contractions.fix('I didn\\'t like this t-shirt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZSkz7gQY9G2t"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import contractions\n",
    "import re\n",
    "\n",
    "# remove some stopwords to capture negation in n-grams if possible\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words.remove('no')\n",
    "stop_words.remove('not')\n",
    "stop_words.remove('but')\n",
    "\n",
    "# load up a simple porter stemmer - nothing fancy\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "def simple_text_preprocessor(document): \n",
    "    # lower case\n",
    "    document = str(document).lower()\n",
    "    \n",
    "    # expand contractions\n",
    "    document = contractions.fix(document)\n",
    "    \n",
    "    # remove unnecessary characters\n",
    "    document = re.sub(r'[^a-zA-Z]',r' ', document)\n",
    "    document = re.sub(r'nbsp', r'', document)\n",
    "    document = re.sub(' +', ' ', document)\n",
    "    \n",
    "    # simple porter stemming\n",
    "    document = ' '.join([ps.stem(word) for word in document.split()])\n",
    "    \n",
    "    # stopwords removal\n",
    "    document = ' '.join([word for word in document.split() if word not in stop_words])\n",
    "    \n",
    "    return document\n",
    "\n",
    "stp = np.vectorize(simple_text_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "u3bHOnew9G2v",
    "outputId": "2d374c5c-dc4b-4d61-ec31-1fd3bf24fb97"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Clean Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12896</th>\n",
       "      <td>Soooo soft! This is a delightfully soft and fl...</td>\n",
       "      <td>268</td>\n",
       "      <td>52</td>\n",
       "      <td>5.056604</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>soooo soft thi delight soft fluffi sweater mig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13183</th>\n",
       "      <td>Had my eye on this, but dind't get I finally v...</td>\n",
       "      <td>399</td>\n",
       "      <td>84</td>\n",
       "      <td>4.694118</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101944</td>\n",
       "      <td>0.719537</td>\n",
       "      <td>eye thi but dind get final visit store petit t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>I wanted to like this... I wanted to like this...</td>\n",
       "      <td>525</td>\n",
       "      <td>104</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.186538</td>\n",
       "      <td>0.458761</td>\n",
       "      <td>want like thi want like thi top badli badli fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5205</th>\n",
       "      <td>Beautiful blouse Bought this for my daughter i...</td>\n",
       "      <td>203</td>\n",
       "      <td>35</td>\n",
       "      <td>5.638889</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>beauti blous bought thi daughter law birthday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13366</th>\n",
       "      <td>Boxy. large. Boxy, unflattering, and large.\\n\\...</td>\n",
       "      <td>295</td>\n",
       "      <td>51</td>\n",
       "      <td>5.673077</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329613</td>\n",
       "      <td>0.510268</td>\n",
       "      <td>boxi larg boxi unflatt larg I curvi pound thi ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  ...                                       Clean Review\n",
       "12896  Soooo soft! This is a delightfully soft and fl...  ...  soooo soft thi delight soft fluffi sweater mig...\n",
       "13183  Had my eye on this, but dind't get I finally v...  ...  eye thi but dind get final visit store petit t...\n",
       "1496   I wanted to like this... I wanted to like this...  ...  want like thi want like thi top badli badli fa...\n",
       "5205   Beautiful blouse Bought this for my daughter i...  ...  beauti blous bought thi daughter law birthday ...\n",
       "13366  Boxy. large. Boxy, unflattering, and large.\\n\\...  ...  boxi larg boxi unflatt larg I curvi pound thi ...\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Clean Review'] = stp(X_train['Review'].values)\n",
    "X_test['Clean Review'] = stp(X_test['Review'].values)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-wYVCWIQ9G2y"
   },
   "source": [
    "## Extracting out the structured features from previous experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "C7jXiEiG9G2y",
    "outputId": "36aeccd5-106c-4fbe-c75c-82d24d57fec9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268</td>\n",
       "      <td>52</td>\n",
       "      <td>5.056604</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.490909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>399</td>\n",
       "      <td>84</td>\n",
       "      <td>4.694118</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101944</td>\n",
       "      <td>0.719537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>525</td>\n",
       "      <td>104</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.186538</td>\n",
       "      <td>0.458761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203</td>\n",
       "      <td>35</td>\n",
       "      <td>5.638889</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>295</td>\n",
       "      <td>51</td>\n",
       "      <td>5.673077</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329613</td>\n",
       "      <td>0.510268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count  word_count  ...  Polarity  Subjectivity\n",
       "0         268          52  ...  0.170455      0.490909\n",
       "1         399          84  ...  0.101944      0.719537\n",
       "2         525         104  ...  0.186538      0.458761\n",
       "3         203          35  ...  0.625000      0.825000\n",
       "4         295          51  ...  0.329613      0.510268\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_metadata = X_train.drop(['Review', 'Clean Review'], axis=1).reset_index(drop=True)\n",
    "X_test_metadata = X_test.drop(['Review', 'Clean Review'], axis=1).reset_index(drop=True)\n",
    "\n",
    "X_train_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r7777OYn9G21"
   },
   "source": [
    "# Experiment 3: Adding Bag of Words based Features - 1-grams\n",
    "\n",
    "This is perhaps the most simple vector space representational model for unstructured text. A vector space model is simply a mathematical model to represent unstructured text (or any other data) as numeric vectors, such that each dimension of the vector is a specific feature\\attribute. \n",
    "\n",
    "The bag of words model represents each text document as a numeric vector where each dimension is a specific word from the corpus and the value could be its frequency in the document, occurrence (denoted by 1 or 0) or even weighted values. \n",
    "\n",
    "The model’s name is such because each document is represented literally as a ‘bag’ of its own words, disregarding word orders, sequences and grammar.\n",
    "\n",
    "Source: https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "SaX1fDmT9G23",
    "outputId": "49a8d0d7-fdf0-4391-c636-015281834d30"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaandidon</th>\n",
       "      <th>aaaaannnnnnd</th>\n",
       "      <th>aaaah</th>\n",
       "      <th>aaaahmaz</th>\n",
       "      <th>aaah</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abbi</th>\n",
       "      <th>abck</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdomin</th>\n",
       "      <th>abercrombi</th>\n",
       "      <th>abil</th>\n",
       "      <th>abject</th>\n",
       "      <th>abl</th>\n",
       "      <th>abnorm</th>\n",
       "      <th>abo</th>\n",
       "      <th>abolut</th>\n",
       "      <th>abou</th>\n",
       "      <th>abov</th>\n",
       "      <th>abroad</th>\n",
       "      <th>abruptli</th>\n",
       "      <th>abso</th>\n",
       "      <th>absolut</th>\n",
       "      <th>absolutley</th>\n",
       "      <th>absolutli</th>\n",
       "      <th>absorb</th>\n",
       "      <th>abstract</th>\n",
       "      <th>absurd</th>\n",
       "      <th>abt</th>\n",
       "      <th>abund</th>\n",
       "      <th>abus</th>\n",
       "      <th>ac</th>\n",
       "      <th>acacia</th>\n",
       "      <th>accent</th>\n",
       "      <th>accentu</th>\n",
       "      <th>accentuatea</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptabl</th>\n",
       "      <th>...</th>\n",
       "      <th>yoga</th>\n",
       "      <th>yogi</th>\n",
       "      <th>yogini</th>\n",
       "      <th>yoke</th>\n",
       "      <th>yolk</th>\n",
       "      <th>yoo</th>\n",
       "      <th>yore</th>\n",
       "      <th>york</th>\n",
       "      <th>yoself</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "      <th>yr</th>\n",
       "      <th>yuck</th>\n",
       "      <th>yucki</th>\n",
       "      <th>yuk</th>\n",
       "      <th>yum</th>\n",
       "      <th>yumi</th>\n",
       "      <th>yummi</th>\n",
       "      <th>yummiest</th>\n",
       "      <th>yummysweat</th>\n",
       "      <th>yup</th>\n",
       "      <th>zag</th>\n",
       "      <th>zara</th>\n",
       "      <th>zermatt</th>\n",
       "      <th>zero</th>\n",
       "      <th>zig</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zing</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zipperi</th>\n",
       "      <th>zippi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zooland</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zowi</th>\n",
       "      <th>zuma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8559 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaaaandidon  aaaaannnnnnd  aaaah  ...  zooland  zoom  zowi  zuma\n",
       "0   0            0             0      0  ...        0     0     0     0\n",
       "1   0            0             0      0  ...        0     0     0     0\n",
       "2   0            0             0      0  ...        0     0     0     0\n",
       "3   0            0             0      0  ...        0     0     0     0\n",
       "4   0            0             0      0  ...        0     0     0     0\n",
       "\n",
       "[5 rows x 8559 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1, 1))\n",
    "X_traincv = cv.fit_transform(X_train['Clean Review']).toarray()\n",
    "X_traincv = pd.DataFrame(X_traincv, columns=cv.get_feature_names())\n",
    "\n",
    "X_testcv = cv.transform(X_test['Clean Review']).toarray()\n",
    "X_testcv = pd.DataFrame(X_testcv, columns=cv.get_feature_names())\n",
    "X_traincv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "AMNdg_cg9G27",
    "outputId": "dcfd5c6a-1293-4e42-fdc8-af4bcb9a7ebb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaandidon</th>\n",
       "      <th>aaaaannnnnnd</th>\n",
       "      <th>aaaah</th>\n",
       "      <th>aaaahmaz</th>\n",
       "      <th>aaah</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abbi</th>\n",
       "      <th>abck</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdomin</th>\n",
       "      <th>abercrombi</th>\n",
       "      <th>abil</th>\n",
       "      <th>abject</th>\n",
       "      <th>abl</th>\n",
       "      <th>abnorm</th>\n",
       "      <th>abo</th>\n",
       "      <th>abolut</th>\n",
       "      <th>abou</th>\n",
       "      <th>abov</th>\n",
       "      <th>abroad</th>\n",
       "      <th>abruptli</th>\n",
       "      <th>abso</th>\n",
       "      <th>absolut</th>\n",
       "      <th>absolutley</th>\n",
       "      <th>absolutli</th>\n",
       "      <th>absorb</th>\n",
       "      <th>abstract</th>\n",
       "      <th>absurd</th>\n",
       "      <th>abt</th>\n",
       "      <th>abund</th>\n",
       "      <th>...</th>\n",
       "      <th>yoga</th>\n",
       "      <th>yogi</th>\n",
       "      <th>yogini</th>\n",
       "      <th>yoke</th>\n",
       "      <th>yolk</th>\n",
       "      <th>yoo</th>\n",
       "      <th>yore</th>\n",
       "      <th>york</th>\n",
       "      <th>yoself</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "      <th>yr</th>\n",
       "      <th>yuck</th>\n",
       "      <th>yucki</th>\n",
       "      <th>yuk</th>\n",
       "      <th>yum</th>\n",
       "      <th>yumi</th>\n",
       "      <th>yummi</th>\n",
       "      <th>yummiest</th>\n",
       "      <th>yummysweat</th>\n",
       "      <th>yup</th>\n",
       "      <th>zag</th>\n",
       "      <th>zara</th>\n",
       "      <th>zermatt</th>\n",
       "      <th>zero</th>\n",
       "      <th>zig</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zing</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zipperi</th>\n",
       "      <th>zippi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zooland</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zowi</th>\n",
       "      <th>zuma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268</td>\n",
       "      <td>52</td>\n",
       "      <td>5.056604</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>399</td>\n",
       "      <td>84</td>\n",
       "      <td>4.694118</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101944</td>\n",
       "      <td>0.719537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>525</td>\n",
       "      <td>104</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.186538</td>\n",
       "      <td>0.458761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203</td>\n",
       "      <td>35</td>\n",
       "      <td>5.638889</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>295</td>\n",
       "      <td>51</td>\n",
       "      <td>5.673077</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329613</td>\n",
       "      <td>0.510268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8567 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count  word_count  word_density  ...  zoom  zowi  zuma\n",
       "0         268          52      5.056604  ...     0     0     0\n",
       "1         399          84      4.694118  ...     0     0     0\n",
       "2         525         104      5.000000  ...     0     0     0\n",
       "3         203          35      5.638889  ...     0     0     0\n",
       "4         295          51      5.673077  ...     0     0     0\n",
       "\n",
       "[5 rows x 8567 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_comb = pd.concat([X_train_metadata, X_traincv], axis=1)\n",
    "X_test_comb = pd.concat([X_test_metadata, X_testcv], axis=1)\n",
    "\n",
    "X_train_comb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OE5qPGfz9G3A"
   },
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "fWaTndc-9G3A",
    "outputId": "2e50b231-5f42-4713-cbba-601dfd7eccb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73      1271\n",
      "           1       0.92      0.93      0.92      4390\n",
      "\n",
      "    accuracy                           0.88      5661\n",
      "   macro avg       0.84      0.82      0.83      5661\n",
      "weighted avg       0.88      0.88      0.88      5661\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>890</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>286</td>\n",
       "      <td>4104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1\n",
       "0  890   381\n",
       "1  286  4104"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_comb, y_train)\n",
    "predictions = lr.predict(X_test_comb)\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "pd.DataFrame(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ePwRpYI9G3E"
   },
   "source": [
    "Wow! This looks promising.\n",
    "\n",
    "We are now able to predict __70%__ of the total number of bad or negative rated products now! \n",
    "Precision is quite good at __76%__\n",
    "\n",
    "__F1-Score__ for bad reviews is now __73%__ and good reviews is __92%__\n",
    "\n",
    "This brings our overall __F1-Score__ to __88%__ which is quite good."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "05 - NLP Applications - Predicting E-Commerce Product Recommendation Ratings from Reviews .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
