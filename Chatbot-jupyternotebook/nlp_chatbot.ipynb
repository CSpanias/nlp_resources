{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk \n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem import wordnet # to perform lemmitization\n",
    "from sklearn.feature_extraction.text import CountVectorizer # to perform bow\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # to perform tfidf\n",
    "from nltk import pos_tag # for parts of speech\n",
    "from sklearn.metrics import pairwise_distances # to perfrom cosine similarity\n",
    "from nltk import word_tokenize # to create tokens\n",
    "from nltk.corpus import stopwords # for stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('dialog_talk_agent.xlsx')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0] # returns the number of rows in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ffill(axis = 0,inplace=True) # fills the null value with the previous value.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.head(10) # copy of first ten rows of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that converts text into lower case and removes special characters\n",
    "\n",
    "def step1(x):\n",
    "    for i in x:\n",
    "        a=str(i).lower()\n",
    "        p=re.sub(r'[^a-z0-9]',' ',a)\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1(df1['Context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # word tokenizing\n",
    "    \n",
    "s='tell me about your personality'\n",
    "words=word_tokenize(s)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = wordnet.WordNetLemmatizer() # intializing lemmatizer\n",
    "lemma.lemmatize('absorbed', pos = 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag(nltk.word_tokenize(s),tagset = None) # returns the parts of speech of every word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that performs text normalization steps\n",
    "\n",
    "def text_normalization(text):\n",
    "    text=str(text).lower() # text to lower case\n",
    "    spl_char_text=re.sub(r'[^ a-z]','',text) # removing special characters\n",
    "    tokens=nltk.word_tokenize(spl_char_text) # word tokenizing\n",
    "    lema=wordnet.WordNetLemmatizer() # intializing lemmatization\n",
    "    tags_list=pos_tag(tokens,tagset=None) # parts of speech\n",
    "    lema_words=[]   # empty list \n",
    "    for token,pos_token in tags_list:\n",
    "        if pos_token.startswith('V'):  # Verb\n",
    "            pos_val='v'\n",
    "        elif pos_token.startswith('J'): # Adjective\n",
    "            pos_val='a'\n",
    "        elif pos_token.startswith('R'): # Adverb\n",
    "            pos_val='r'\n",
    "        else:\n",
    "            pos_val='n' # Noun\n",
    "        lema_token=lema.lemmatize(token,pos_val) # performing lemmatization\n",
    "        lema_words.append(lema_token) # appending the lemmatized token into a list\n",
    "    \n",
    "    return \" \".join(lema_words) # returns the lemmatized tokens as a sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_normalization('telling you some stuff about me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized_text']=df['Context'].apply(text_normalization) # applying the fuction to the dataset to get clean text\n",
    "df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the stop words we have \n",
    "\n",
    "stop = stopwords.words('english')\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer() # intializing the count vectorizer\n",
    "X = cv.fit_transform(df['lemmatized_text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns all the unique word from data \n",
    "\n",
    "features = cv.get_feature_names()\n",
    "df_bow = pd.DataFrame(X, columns = features)\n",
    "df_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question ='Will you help me and tell me about yourself more' # considering an example query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for stop words\n",
    "\n",
    "Q=[]\n",
    "a=Question.split()\n",
    "for i in a:\n",
    "    if i in stop:\n",
    "        continue\n",
    "    else:\n",
    "        Q.append(i)\n",
    "    b=\" \".join(Q) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_lemma = text_normalization(b) # applying the function that we created for text normalizing\n",
    "Question_bow = cv.transform([Question_lemma]).toarray() # applying bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity for the above question we considered.\n",
    "\n",
    "cosine_value = 1- pairwise_distances(df_bow, Question_bow, metric = 'cosine' )\n",
    "(cosine_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['similarity_bow']=cosine_value # creating a new column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simi = pd.DataFrame(df, columns=['Text Response','similarity_bow']) # taking similarity value of responses for the question we took\n",
    "df_simi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simi_sort = df_simi.sort_values(by='similarity_bow', ascending=False) # sorting the values\n",
    "df_simi_sort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.2 # considering the value of p=smiliarity to be greater than 0.2\n",
    "df_threshold = df_simi_sort[df_simi_sort['similarity_bow'] > threshold] \n",
    "df_threshold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finally using bow for the question 'Will you help me and tell me about yourself more' , the above are the responses we got using bow and the smiliarity value of responses, we consider the response with highest similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_value = cosine_value.argmax() # returns the index number of highest value\n",
    "index_value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text Response'].loc[index_value] # The text at the above index becomes the response for the question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question1 ='Tell me about yourself.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_lemma1 = text_normalization(Question1)\n",
    "Question_tfidf = tfidf.transform([Question_lemma1]).toarray() # applying tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using tf-idf\n",
    "\n",
    "tfidf=TfidfVectorizer() # intializing tf-id \n",
    "x_tfidf=tfidf.fit_transform(df['lemmatized_text']).toarray() # transforming the data into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns all the unique word from data with a score of that word\n",
    "\n",
    "df_tfidf=pd.DataFrame(x_tfidf,columns=tfidf.get_feature_names()) \n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos=1-pairwise_distances(df_tfidf,Question_tfidf,metric='cosine')  # applying cosine similarity\n",
    "cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['similarity_tfidf']=cos # creating a new column \n",
    "df_simi_tfidf = pd.DataFrame(df, columns=['Text Response','similarity_tfidf']) # taking similarity value of responses for the question we took\n",
    "df_simi_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simi_tfidf_sort = df_simi_tfidf.sort_values(by='similarity_tfidf', ascending=False) # sorting the values\n",
    "df_simi_tfidf_sort.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.2 # considering the value of p=smiliarity to be greater than 0.2\n",
    "df_threshold = df_simi_tfidf_sort[df_simi_tfidf_sort['similarity_tfidf'] > threshold] \n",
    "df_threshold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- by using tfidf for the question 'Will you help me and tell me about yourself more' , the above are the responses we got and the smiliarity value of responses, we consider the response with highest similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_value1 = cos.argmax() # returns the index number of highest value\n",
    "index_value1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text Response'].loc[index_value1]  # returns the text at that index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that removes stop words and process the text\n",
    "\n",
    "def stopword_(text):   \n",
    "    tag_list=pos_tag(nltk.word_tokenize(text),tagset=None)\n",
    "    stop=stopwords.words('english')\n",
    "    lema=wordnet.WordNetLemmatizer()\n",
    "    lema_word=[]\n",
    "    for token,pos_token in tag_list:\n",
    "        if token in stop:\n",
    "            continue\n",
    "        if pos_token.startswith('V'):\n",
    "            pos_val='v'\n",
    "        elif pos_token.startswith('J'):\n",
    "            pos_val='a'\n",
    "        elif pos_token.startswith('R'):\n",
    "            pos_val='r'\n",
    "        else:\n",
    "            pos_val='n'\n",
    "        lema_token=lema.lemmatize(token,pos_val)\n",
    "        lema_word.append(lema_token)\n",
    "    return \" \".join(lema_word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function that returns response to query using bow\n",
    "\n",
    "def chat_bow(text):\n",
    "    s=stopword_(text)\n",
    "    lemma=text_normalization(s) # calling the function to perform text normalization\n",
    "    bow=cv.transform([lemma]).toarray() # applying bow\n",
    "    cosine_value = 1- pairwise_distances(df_bow,bow, metric = 'cosine' )\n",
    "    index_value=cosine_value.argmax() # getting index value \n",
    "    return df['Text Response'].loc[index_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_bow('hi there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_bow('Your are amazing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_bow('i miss you')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function that returns response to query using tf-idf\n",
    "\n",
    "def chat_tfidf(text):\n",
    "    lemma=text_normalization(text) # calling the function to perform text normalization\n",
    "    tf=tfidf.transform([lemma]).toarray() # applying tf-idf\n",
    "    cos=1-pairwise_distances(df_tfidf,tf,metric='cosine') # applying cosine similarity\n",
    "    index_value=cos.argmax() # getting index value \n",
    "    return df['Text Response'].loc[index_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_tfidf('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_tfidf('how are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_tfidf('i love you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_tfidf('thanks for your support!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_tfidf('will you reply accurately?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_tfidf('will you marry me?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_tfidf('i miss you and i love you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_tfidf('ask sravya to read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_tfidf('you are amazing and hope to see u soon.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "- Our chat bot worked well with both bow and tf-idf, tf-idf model worked well even with stop words compared to bow where we had to remove stop words before using bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Diamond is hard', 'Diamond has high strength']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['Diamond is hard', 'Diamond has high strength']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import bigrams\n",
    "\n",
    "my_list = ['Diamond', 'is hard', 'has high strength']\n",
    "\n",
    "def convert_to_bigrams(my_list):\n",
    "    final_list = []\n",
    "    # save 1st word as a base\n",
    "    base_word = my_list[0]\n",
    "    # convert list to bigrams dict\n",
    "    bigrams_dict =  dict(bigrams(my_list))\n",
    "    # obtain dict's values\n",
    "    for value in bigrams_dict.values():\n",
    "        # join base_word and each dict's value\n",
    "        final_list.append(base_word + \" \" + value)\n",
    "    \n",
    "    return final_list\n",
    "\n",
    "# invoke function\n",
    "convert_to_bigrams(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dog is a mammal', 'Dog has 4 legs', 'Dog is barking']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['Dog is a mammal', 'Dog has 4 legs', 'Dog is barking']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list_2 = [\"Dog\", \"is a mammal\", \"has 4 legs\", \"is barking\"]\n",
    "\n",
    "convert_to_bigrams(my_list_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
