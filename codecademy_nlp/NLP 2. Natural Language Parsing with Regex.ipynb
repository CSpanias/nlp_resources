{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d6a6825",
   "metadata": {},
   "source": [
    "# Natural Language Parsing with Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4220556d",
   "metadata": {},
   "source": [
    "```complile``` from ```re```  \n",
    "takes a **regex** as an argument & compiles the pattern into a **regex object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2089b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# define characters\n",
    "character_1 = \"Dorothy\"\n",
    "character_2 = \"Henry\"\n",
    "\n",
    "# compile regular expression, any upper- or lower-case letter x 7\n",
    "regular_expression = re.compile(\"[A-Za-z]{7}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a2a3be",
   "metadata": {},
   "source": [
    "```match()``` from ```re```  \n",
    "Takes a **string** as an argument and looks for a **single match** to the regex that starts at the **beginning of the string**.  \n",
    "If matched, returns a **match object**, if not ```None```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bba3764c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 7), match='Dorothy'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# check for a match to character_1\n",
    "result_1 = regular_expression.match(character_1)\n",
    "print(result_1)\n",
    "\n",
    "# check for a match to character_2\n",
    "result_2 = re.match(\"[A-Za-z]{7}\", character_2)\n",
    "print(result_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a607e529",
   "metadata": {},
   "source": [
    "Access the matched texted by ```group()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e55d879e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dorothy\n"
     ]
    }
   ],
   "source": [
    "# store and print the matched text\n",
    "match_1 = result_1.group()\n",
    "print(match_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce26a2f",
   "metadata": {},
   "source": [
    "```search()```  \n",
    "Looks left to right and returns a **match object** for the **first match**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b4d2b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 3), match='Mic'>\n"
     ]
    }
   ],
   "source": [
    "name = \"Michael\"\n",
    "result = re.search(\"\\w{3}\", name)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8147937",
   "metadata": {},
   "source": [
    "```findall()```  \n",
    "Returns a list of **all non-overlapping matches**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d0f8e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mic', 'hae']\n"
     ]
    }
   ],
   "source": [
    "result_a = re.findall('\\w{3}', name)\n",
    "print(result_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f019fa84",
   "metadata": {},
   "source": [
    "<a name=\"POS\"> </a>\n",
    "## Part-of-Speech (POS) Tagging\n",
    "\n",
    "```pos_tag()```  \n",
    "Takes a **list of words** as an argument, returns a **list of tuples** (word, tag)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59fc8215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natural', 'language', 'processing', 'awesome']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "text = '   Natural Language Processing is awesome!'\n",
    "\n",
    "# lower case letters\n",
    "text_lower = text.lower()\n",
    "\n",
    "# remove whitespace\n",
    "text_nowhite = re.sub(r'\\s{2,9}', '', text_lower)\n",
    "                      \n",
    "# remove punctuation\n",
    "text_nopunc = re.sub(r'\\!', '', text_nowhite)\n",
    "\n",
    "# split sentence into individual words\n",
    "text_tokenized = word_tokenize(text_nopunc)\n",
    "\n",
    "# remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "text_clean = [token for token in text_tokenized if token not in stop_words]\n",
    "\n",
    "print(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4e76677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('awesome', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "pos_tagged = pos_tag(text_clean)\n",
    "print(pos_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc86838c",
   "metadata": {},
   "source": [
    "<a name=\"Chunking\"> </a>\n",
    "### Chunking\n",
    "Grouping words by their POS tag.\n",
    "\n",
    "**Chunk grammar**: the regex for finding chunks (non-overlapping matches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53d54019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (AN natural/JJ language/NN) processing/NN awesome/NN)\n"
     ]
    }
   ],
   "source": [
    "from nltk import RegexpParser\n",
    "\n",
    "# AN = ADJECTIVE followed by NOUN\n",
    "chunk_grammar = \"AN: {<JJ><NN>}\"\n",
    "\n",
    "# instantiate RegexpParser with the defined chunk grammar\n",
    "chunk_parser = RegexpParser(chunk_grammar)\n",
    "\n",
    "# parse the tagged text\n",
    "chunked_text = chunk_parser.parse(pos_tagged)\n",
    "print(chunked_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df97c15",
   "metadata": {},
   "source": [
    "Visualize chunking results with ```Tree```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83353b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  S                                \n",
      "       ___________|__________________               \n",
      "      |           |                  AN            \n",
      "      |           |           _______|_______       \n",
      "processing/NN awesome/NN natural/JJ     language/NN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk import Tree\n",
    "\n",
    "Tree.fromstring(str(chunked_text)).pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e88a958",
   "metadata": {},
   "source": [
    "Certain types of chunking are **linguistically helpful** for determining **meaning** and **bias**.\n",
    "\n",
    "### Chunking Noun Phrases (NP-chunking)\n",
    "1. Begins with a **determiner** ```DT``` which specifies the noun being referenced,\n",
    "2. followed by any number of **adjectives** ```JJ``` which describe the noun,\n",
    "3. ends with a **noun** ```NN```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7622e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ? = 0 or 1, * = 0 or more\n",
    "np_grammar = \"NP: {<DT>?<JJ>*<NN>}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa08e1e",
   "metadata": {},
   "source": [
    "### Chunking Verb Phrases (VB-Chunking)\n",
    "A phrase that contains a **verb** and its **complements**, **objects**, or **modifiers**.\n",
    "\n",
    "Finding all verb phrases can give insight into what kind of **action** different characters take or how the actions are **described** by the author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bcc0ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VB.* = ensures matching verbs of any tense, RB.? = ensures matching any adverb form\n",
    "vp_grammar_a = \"VB: {<VB.*><DT>?<JJ>*<NN><RB.?>?}\"\n",
    "vp_grammar_b = \"VB: {<DT>?<JJ>*<NN><VB.*><RB.?>?}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c08d86",
   "metadata": {},
   "source": [
    "### Chunk Filtering\n",
    "Lets you define what POS you **do not want** in a chunk and remove them.\n",
    "\n",
    "1. Chunk an entire sentence together\n",
    "2. Indicate POS filtering\n",
    "\n",
    "An alternative way to search through a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0436aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matches every POS in the sentence\n",
    "chunk_filtering_grammar = \"\"\"NP: {<.*>+}\n",
    "                        }<VB.?|IN>{\"\"\" # filter any verbs or prepositions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
